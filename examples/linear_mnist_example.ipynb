{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This simple notebook demonstrates the workflow of using the TensorFlow converter.\n",
    "\"\"\"\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data # Import MINST data\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "image_input:  Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "pred output: Tensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "Epoch: 0001 cost= 1.184098856\n",
      "Epoch: 0002 cost= 0.665214666\n",
      "Epoch: 0003 cost= 0.552832297\n",
      "Epoch: 0004 cost= 0.498685127\n",
      "Epoch: 0005 cost= 0.465539188\n",
      "Epoch: 0006 cost= 0.442591051\n",
      "Epoch: 0007 cost= 0.425546707\n",
      "Epoch: 0008 cost= 0.412170771\n",
      "Epoch: 0009 cost= 0.401374561\n",
      "Epoch: 0010 cost= 0.392460415\n",
      "Epoch: 0011 cost= 0.384782734\n",
      "Epoch: 0012 cost= 0.378175704\n",
      "Epoch: 0013 cost= 0.372433835\n",
      "Epoch: 0014 cost= 0.367307418\n",
      "Epoch: 0015 cost= 0.362708040\n",
      "Epoch: 0016 cost= 0.358616659\n",
      "Epoch: 0017 cost= 0.354869177\n",
      "Epoch: 0018 cost= 0.351474552\n",
      "Epoch: 0019 cost= 0.348326069\n",
      "Epoch: 0020 cost= 0.345428566\n",
      "Epoch: 0021 cost= 0.342733337\n",
      "Epoch: 0022 cost= 0.340201485\n",
      "Epoch: 0023 cost= 0.337922069\n",
      "Epoch: 0024 cost= 0.335763353\n",
      "Epoch: 0025 cost= 0.333702896\n",
      "Training Done. Now save the checkpoint...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 0: Before you run this notebook, view run the example script linear_mnist_train.py\n",
    "to get a trained TensorFlow network.\n",
    "This may take a few minutes.\n",
    "\"\"\"\n",
    "import linear_mnist_train\n",
    "linear_mnist_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n",
      "8 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: \"Freeze\" your tensorflow model - convert your TF model into a stand-alone graph definition file\n",
    "Inputs: \n",
    "(1) TensorFlow code\n",
    "(2) trained weights in a checkpoint file\n",
    "(3) The output tensors' name you want to use in inference\n",
    "(4) [Optional] Input tensors' name to TF model\n",
    "Outputs: \n",
    "(1) A frozen TensorFlow GraphDef, with trained weights frozen into it\n",
    "\"\"\"\n",
    "\n",
    "# Provide these to run freeze_graph:\n",
    "# Graph definition file, stored as protobuf TEXT\n",
    "graph_def_file = './model.pbtxt'\n",
    "# Trained model's checkpoint name\n",
    "checkpoint_file = './checkpoints/model.ckpt'\n",
    "# Frozen model's output name\n",
    "frozen_model_file = './frozen_model.pb'\n",
    "# Output nodes. If there're multiple output ops, use comma separated string, e.g. \"out1,out2\".\n",
    "output_node_names = 'Softmax' \n",
    "\n",
    "\n",
    "# Call freeze graph\n",
    "freeze_graph(input_graph=graph_def_file,\n",
    "             input_saver=\"\",\n",
    "             input_binary=False,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=output_node_names,\n",
    "             restore_op_name=\"save/restore_all\",\n",
    "             filename_tensor_name=\"save/Const:0\",\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfcoreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 4 tensors. Executing graph to determine shapes. \n",
      "2/8: Converting op name: Variable_1/read ( type:  Identity )\n",
      "4/8: Converting op name: Variable/read ( type:  Identity )\n",
      "5/8: Converting op name: Placeholder ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "6/8: Converting op name: MatMul ( type:  MatMul )\n",
      "8/8: Converting op name: Softmax ( type:  Softmax )\n",
      "\n",
      " Core ML model generated. Saved at location: ./model.mlmodel \n",
      "\n",
      "Core ML input(s):  [('Placeholder:0', Array({784}))]\n",
      "Core ML output(s):  [('Softmax:0', Array({10}))]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 2: Call converter\n",
    "\"\"\"\n",
    "\n",
    "# Provide these inputs in addition to inputs in Step 1\n",
    "# A dictionary of input tensors' name and shape (with batch)\n",
    "input_tensor_shapes = {\"Placeholder:0\":[1,784]} # batch size is 1\n",
    "# Output CoreML model path\n",
    "coreml_model_file = './model.mlmodel'\n",
    "output_tensor_names = ['Softmax:0']\n",
    "\n",
    "\n",
    "# Call the converter\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "        output_feature_names=output_tensor_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: Run the converted model\n",
    "\"\"\"\n",
    "\n",
    "# Provide CoreML model with a dictionary as input. Change ':0' to '__0'\n",
    "# as Swift / Objective-C code generation do not allow colons in variable names\n",
    "coreml_inputs = {'Placeholder__0': np.random.rand(1,1,784)} # (sequence_length=1,batch=1,channels=784)\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Softmax__0': array([  2.20795218e-02,   3.88212356e-05,   2.50600070e-01,\n",
      "         1.08398639e-01,   1.32157514e-03,   5.56724310e-01,\n",
      "         1.16459439e-02,   2.66482867e-03,   4.52293456e-02,\n",
      "         1.29695563e-03])}\n"
     ]
    }
   ],
   "source": [
    "print coreml_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
